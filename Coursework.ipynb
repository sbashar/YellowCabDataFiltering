{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(VendorID=2, tpep_pickup_datetime=u'01/01/2016 00:00', tpep_dropoff_datetime=u'01/01/2016 00:00', passenger_count=2, trip_distance=1.1, pickup_longitude=-73.9903717, pickup_latitude=40.73469543, RatecodeID=1, store_and_fwd_flag=u'N', dropoff_longitude=-73.98184204, dropoff_latitude=40.73240662, payment_type=2, fare_amount=7.5, extra=0.5, mta_tax=0.5, tip_amount=0, tolls_amount=0, improvement_surcharge=0.3, total_amount=8.8)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "from dateutil.parser import parse\n",
    "from datetime import datetime\n",
    "\n",
    "def date_and_hour_and_minute(s):\n",
    "    dt = parse(s.replace('?',' '))\n",
    "    hour = dt.hour\n",
    "    minute = dt.minute\n",
    "    return (dt.strftime(\"%Y-%m-%d\"),hour, minute)\n",
    "\n",
    "def check_empty_column(row):\n",
    "    for column in row:\n",
    "        if column == '' or column == None:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "sqlContext = SQLContext(sc)\n",
    "df = sqlContext.read.format('com.databricks.spark.csv').options(header='true',inferschema='true').load('file:///home/oxclo/BigDataAndCloudComputing/test_data_empty_column.csv')\n",
    "yellowcabdata = df.rdd\n",
    "\n",
    "filteremptycolumn = yellowcabdata.filter(lambda x: check_empty_column(x))\n",
    "filteremptycolumn.take(5)\n",
    "\n",
    "#mapped = yellowcabdata.map(lambda x: (x.tpep_pickup_datetime, x.tpep_dropoff_datetime, x.trip_distance, x.pickup_longitude, x.))\n",
    "#mapped.take(1)\n",
    "#mapped = winddata.map(lambda x: (x.Station_ID, date_and_hour(x.Interval_End_Time),x.Wind_Velocity_Mtr_Sec, x.Ambient_Temperature_Deg_C))\n",
    "#filtered = mapped.filter(lambda (a,b,c,d): c != 0.0 and d != 0.0 and bool(c) and bool(d))\n",
    "#combinedstationdatetime = filtered.map(lambda (s,(d,h),v,t): ((s,d,h),(v,t)))\n",
    "#keyvalueone = combinedstationdatetime.map(lambda (station_date_hour,(v,t)): (station_date_hour,(v,t,1)))\n",
    "#sumdata = keyvalueone.reduceByKey(lambda (v1,t1,c1),(v2,t2,c2):(v1+v2,t1+t2,c1+c2))\n",
    "#averagedata = sumdata.map(lambda((s,d,h),(v,t,c)):((s,d,h),v/c,t/c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
